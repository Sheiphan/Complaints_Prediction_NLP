{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "\n",
    "# NLP Module\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize, FreqDist\n",
    "import string\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Classification model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,ConfusionMatrixDisplay,\\\n",
    "                            precision_score,recall_score,f1_score,roc_auc_score, roc_curve\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Preprocessing models\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from category_encoders.binary import BinaryEncoder\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "# Hyperparameters tuning models\n",
    "from hyperopt import tpe,hp,Trials,space_eval\n",
    "from hyperopt.fmin import fmin\n",
    "from hyperopt.pyll import scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768358, 18)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Complaints.csv')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>85.881191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "      <td>78.651358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Company public response</th>\n",
       "      <td>74.528931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consumer consent provided?</th>\n",
       "      <td>61.237210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sub-issue</th>\n",
       "      <td>59.265342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sub-product</th>\n",
       "      <td>30.605525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <td>0.735334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZIP code</th>\n",
       "      <td>0.501980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date sent to company</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consumer disputed?</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timely response?</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Company response to consumer</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date received</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Submitted via</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Company</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Issue</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Complaint ID</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      0\n",
       "Tags                          85.881191\n",
       "Consumer complaint narrative  78.651358\n",
       "Company public response       74.528931\n",
       "Consumer consent provided?    61.237210\n",
       "Sub-issue                     59.265342\n",
       "Sub-product                   30.605525\n",
       "State                          0.735334\n",
       "ZIP code                       0.501980\n",
       "Date sent to company           0.000000\n",
       "Consumer disputed?             0.000000\n",
       "Timely response?               0.000000\n",
       "Company response to consumer   0.000000\n",
       "Date received                  0.000000\n",
       "Submitted via                  0.000000\n",
       "Product                        0.000000\n",
       "Company                        0.000000\n",
       "Issue                          0.000000\n",
       "Complaint ID                   0.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = df.isnull().sum().div(df.shape[0]).mul(100).to_frame().sort_values(by=0, ascending=False)\n",
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "drop_columns = ['Tags','Consumer complaint narrative','Company public response',\n",
    "                'Consumer consent provided?','Sub-issue','Sub-product','Complaint ID','ZIP code']\n",
    "df.drop(drop_columns, axis=1,inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date received</th>\n",
       "      <th>Date sent to company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>2015-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-09-04</td>\n",
       "      <td>2013-09-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-06-10</td>\n",
       "      <td>2014-06-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-08</td>\n",
       "      <td>2014-01-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-09-11</td>\n",
       "      <td>2014-09-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Date received Date sent to company\n",
       "0    2015-01-04           2015-01-04\n",
       "1    2013-09-04           2013-09-03\n",
       "2    2014-06-10           2014-06-10\n",
       "3    2014-01-08           2014-01-08\n",
       "4    2014-09-11           2014-09-18"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Date received','Date sent to company']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date received</th>\n",
       "      <th>Product</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Company</th>\n",
       "      <th>State</th>\n",
       "      <th>Submitted via</th>\n",
       "      <th>Date sent to company</th>\n",
       "      <th>Company response to consumer</th>\n",
       "      <th>Timely response?</th>\n",
       "      <th>Consumer disputed?</th>\n",
       "      <th>days_to_forward_complaint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Incorrect information on credit report</td>\n",
       "      <td>Experian Information Solutions Inc.</td>\n",
       "      <td>TX</td>\n",
       "      <td>Web</td>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-09-04</td>\n",
       "      <td>Credit card</td>\n",
       "      <td>Credit determination</td>\n",
       "      <td>CITIBANK, N.A.</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Web</td>\n",
       "      <td>2013-09-03</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-06-10</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>Disclosure verification of debt</td>\n",
       "      <td>SYNCHRONY FINANCIAL</td>\n",
       "      <td>CO</td>\n",
       "      <td>Web</td>\n",
       "      <td>2014-06-10</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Date received           Product                                   Issue  \\\n",
       "0    2015-01-04  Credit reporting  Incorrect information on credit report   \n",
       "1    2013-09-04       Credit card                    Credit determination   \n",
       "2    2014-06-10   Debt collection         Disclosure verification of debt   \n",
       "\n",
       "                               Company State Submitted via  \\\n",
       "0  Experian Information Solutions Inc.    TX           Web   \n",
       "1                       CITIBANK, N.A.    AZ           Web   \n",
       "2                  SYNCHRONY FINANCIAL    CO           Web   \n",
       "\n",
       "  Date sent to company Company response to consumer Timely response?  \\\n",
       "0           2015-01-04      Closed with explanation              Yes   \n",
       "1           2013-09-03      Closed with explanation              Yes   \n",
       "2           2014-06-10      Closed with explanation              Yes   \n",
       "\n",
       "  Consumer disputed?  days_to_forward_complaint  \n",
       "0                 No                          0  \n",
       "1                 No                         -1  \n",
       "2                 No                          0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['days_to_forward_complaint']=pd.to_datetime(df['Date sent to company'])-pd.to_datetime(df['Date received'])\n",
    "df['days_to_forward_complaint'] = df['days_to_forward_complaint'].dt.days\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Date received','Date sent to company'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For models to reduce computation time we can use sample of the data for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.groupby('Consumer disputed?').sample(n=50000)\n",
    "df1.reset_index(inplace=True)\n",
    "df1.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text processing\n",
    "\n",
    "##### For Vectorization\n",
    "* TFIDF\n",
    "* CountVectorizer\n",
    "* NLTK/Scipy Library\n",
    "* Pretrained Glove\n",
    "\n",
    "##### Steps for text processing\n",
    "* Remove punctuation\n",
    "* Remove Stop Words\n",
    "* Lower Casing\n",
    "* Tokenization\n",
    "* Stemming/Lemmatization\n",
    "\n",
    "\n",
    "##### Note\n",
    "* `Issue` column has text which has to be preprocessed.\n",
    "* The text need to be transformed into vectors as the algorithm will be able to make predictions. In this case, it will be used the Term Frequency-Inverse Document Frequency (TFIDF) weight to evaluate how import a word is to a document in a collection of documents.\n",
    "* After removing the punctuation and lower casing the words, the importance of the word is determined in terms of the frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of stopword which will be remmoved\n",
    "stopwords_list = stopwords.words('english')+list(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(issue):\n",
    "    \"\"\"\n",
    "    Tokenizes the input text, removes stopwords and non-alphabetic words.\n",
    "\n",
    "    Args:\n",
    "        issue (str): The input text to be processed.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of processed tokens.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Tokenize the input text\n",
    "    tokens = nltk.word_tokenize(issue)\n",
    "\n",
    "    # Remove stopwords and convert tokens to lowercase\n",
    "    stopwords_removed = [token.lower() for token in tokens if token.lower() not in stopwords_list]\n",
    "\n",
    "    # Remove non-alphabetic words\n",
    "    stopwords_removed = [word for word in stopwords_removed if word.isalpha()]\n",
    "\n",
    "    return stopwords_removed\n",
    "\n",
    "def concat_strings(words_list):\n",
    "    \"\"\"\n",
    "    Concatenates a list of words into a single string.\n",
    "\n",
    "    Args:\n",
    "        words_list (list): The list of words to be concatenated.\n",
    "\n",
    "    Returns:\n",
    "        str: The concatenated string.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    concat_words = ''\n",
    "    for word in words_list:\n",
    "        concat_words += word + ' '\n",
    "    return concat_words.strip()\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatizer_concat(words_list):\n",
    "    \"\"\"\n",
    "    Lemmatizes each word in the given list and concatenates them into a single string.\n",
    "\n",
    "    Args:\n",
    "        words_list (list): The list of words to be lemmatized and concatenated.\n",
    "\n",
    "    Returns:\n",
    "        str: The lemmatized and concatenated string.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Filter out any NaN values in the list\n",
    "    list_of_words = [i for i in words_list if i is not np.nan]\n",
    "\n",
    "    lemmatized_list = []\n",
    "    for idx, word in enumerate(words_list):\n",
    "        # Lemmatize each word\n",
    "        lemmatized_list.append(lemmatizer.lemmatize(word))\n",
    "\n",
    "    return concat_strings(lemmatized_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'Product', 'Issue', 'Company', 'State', 'Submitted via',\n",
       "       'Company response to consumer', 'Timely response?',\n",
       "       'Consumer disputed?', 'days_to_forward_complaint'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sheip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sheip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "C:\\Users\\sheip\\AppData\\Local\\Temp\\ipykernel_21316\\3175952262.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['Issue'].loc[i] = final_texts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Row Number 0\n",
      "Processed Row Number 5000\n",
      "Processed Row Number 10000\n",
      "Processed Row Number 15000\n",
      "Processed Row Number 20000\n",
      "Processed Row Number 25000\n",
      "Processed Row Number 30000\n",
      "Processed Row Number 35000\n",
      "Processed Row Number 40000\n",
      "Processed Row Number 45000\n",
      "Processed Row Number 50000\n",
      "Processed Row Number 55000\n",
      "Processed Row Number 60000\n",
      "Processed Row Number 65000\n",
      "Processed Row Number 70000\n",
      "Processed Row Number 75000\n",
      "Processed Row Number 80000\n",
      "Processed Row Number 85000\n",
      "Processed Row Number 90000\n",
      "Processed Row Number 95000\n"
     ]
    }
   ],
   "source": [
    "# Prepare data with text processing\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "for i in range(len(df1)):\n",
    "    \n",
    "    # Iterate through all the rows and extract each 'Issue'\n",
    "    text = process_text(df1['Issue'].loc[i])\n",
    "    final_texts = lemmatizer_concat(text)\n",
    "    \n",
    "    # Change the 'Issue' column into the processed text\n",
    "    df1['Issue'].loc[i] = final_texts\n",
    "    if i % 5000 == 0:\n",
    "        print(f'Processed Row Number {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 61)\t0.3941107517958608\n",
      "  (0, 200)\t0.39145579484858417\n",
      "  (0, 1)\t0.3941107517958608\n",
      "  (0, 183)\t0.3941107517958608\n",
      "  (0, 59)\t0.39145579484858417\n",
      "  (0, 199)\t0.39145579484858417\n",
      "  (0, 0)\t0.2726118632691794\n",
      "  (1, 66)\t0.39025256636371786\n",
      "  (1, 191)\t0.39025256636371786\n",
      "  (1, 178)\t0.39025256636371786\n",
      "  (1, 134)\t0.39025256636371786\n",
      "  (1, 64)\t0.3880780552943303\n",
      "  (1, 190)\t0.39025256636371786\n",
      "  (1, 175)\t0.2964963663042613\n",
      "  (2, 86)\t0.3804592048131404\n",
      "  (2, 157)\t0.38840805928471306\n",
      "  (2, 154)\t0.38840805928471306\n",
      "  (2, 240)\t0.3804592048131404\n",
      "  (2, 80)\t0.3272346481531677\n",
      "  (2, 156)\t0.38840805928471306\n",
      "  (2, 152)\t0.38837689226063243\n",
      "  (3, 86)\t0.3804592048131404\n",
      "  (3, 157)\t0.38840805928471306\n",
      "  (3, 154)\t0.38840805928471306\n",
      "  (3, 240)\t0.3804592048131404\n",
      "  :\t:\n",
      "  (99997, 198)\t0.37829665956400904\n",
      "  (99997, 203)\t0.37829665956400904\n",
      "  (99997, 17)\t0.37829665956400904\n",
      "  (99997, 40)\t0.37829665956400904\n",
      "  (99997, 197)\t0.37829665956400904\n",
      "  (99997, 202)\t0.37829665956400904\n",
      "  (99997, 16)\t0.37596519011242724\n",
      "  (99998, 121)\t0.35089502627429797\n",
      "  (99998, 212)\t0.35089502627429797\n",
      "  (99998, 261)\t0.35089502627429797\n",
      "  (99998, 179)\t0.35089502627429797\n",
      "  (99998, 120)\t0.35089502627429797\n",
      "  (99998, 210)\t0.3408923459546742\n",
      "  (99998, 260)\t0.35089502627429797\n",
      "  (99998, 175)\t0.23658146724096837\n",
      "  (99998, 0)\t0.298425369302591\n",
      "  (99999, 121)\t0.35089502627429797\n",
      "  (99999, 212)\t0.35089502627429797\n",
      "  (99999, 261)\t0.35089502627429797\n",
      "  (99999, 179)\t0.35089502627429797\n",
      "  (99999, 120)\t0.35089502627429797\n",
      "  (99999, 210)\t0.3408923459546742\n",
      "  (99999, 260)\t0.35089502627429797\n",
      "  (99999, 175)\t0.23658146724096837\n",
      "  (99999, 0)\t0.298425369302591\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['account', 'account opening', 'account term', 'acct',\n",
       "       'acct credited', 'acct wrong', 'action', 'adding', 'adding money',\n",
       "       'advance', 'advance fee', 'advertising', 'advertising marketing',\n",
       "       'amount', 'amount charged', 'amt', 'application',\n",
       "       'application originator', 'application processing', 'applied',\n",
       "       'applied receive', 'apply', 'apr', 'apr interest', 'arbitration',\n",
       "       'atm', 'atm card', 'attempt', 'attempt collect', 'available',\n",
       "       'available promised', 'balance', 'balance transfer', 'bank',\n",
       "       'bank account', 'bank acct', 'bankruptcy', 'billing',\n",
       "       'billing dispute', 'billing statement', 'broker', 'ca',\n",
       "       'ca contact', 'ca repay', 'ca stop', 'card', 'card protection',\n",
       "       'cash', 'cash advance', 'caused', 'caused fund', 'change',\n",
       "       'charge', 'charge bank', 'charged', 'charged bank', 'charged fee',\n",
       "       'charged received', 'check', 'closing', 'closing account',\n",
       "       'closing management', 'collect', 'collect debt', 'collection',\n",
       "       'collection debt', 'collection foreclosure', 'collection practice',\n",
       "       'communication', 'communication tactic', 'company',\n",
       "       'company investigation', 'cont', 'cont attempt', 'contact',\n",
       "       'contact lender', 'contact sharing', 'convenience',\n",
       "       'convenience check', 'cost', 'credit', 'credit card',\n",
       "       'credit decision', 'credit determination', 'credit line',\n",
       "       'credit monitoring', 'credit report', 'credit reporting',\n",
       "       'credit score', 'credited', 'customer', 'customer relation',\n",
       "       'customer service', 'damaged', 'damaged destroyed', 'day',\n",
       "       'day amt', 'dealing', 'dealing lender', 'debit', 'debit atm',\n",
       "       'debt', 'debt dispute', 'debt owed', 'debt protection', 'decision',\n",
       "       'decision underwriting', 'delay', 'delinquent',\n",
       "       'delinquent account', 'deposit', 'deposit withdrawal', 'destroyed',\n",
       "       'destroyed vehicle', 'determination', 'disclosure',\n",
       "       'disclosure info', 'disclosure verification', 'dispute',\n",
       "       'embezzlement', 'escrow', 'escrow account', 'excessive',\n",
       "       'excessive fee', 'exchange', 'exchange rate', 'expect', 'false',\n",
       "       'false statement', 'feature', 'fee', 'fee interest', 'forbearance',\n",
       "       'forbearance workout', 'foreclosure', 'fraud',\n",
       "       'fraud embezzlement', 'fraud scam', 'fund', 'fund low', 'get',\n",
       "       'get credit', 'getting', 'getting loan', 'identity',\n",
       "       'identity protection', 'identity theft', 'illegal',\n",
       "       'illegal action', 'improper', 'improper contact', 'improper use',\n",
       "       'incorrect', 'incorrect exchange', 'incorrect information', 'info',\n",
       "       'information', 'information credit', 'interest', 'interest expect',\n",
       "       'interest rate', 'investigation', 'issuance', 'issuance credit',\n",
       "       'issue', 'late', 'late fee', 'lease', 'lender', 'lender damaged',\n",
       "       'lender repossessed', 'lender servicer', 'lender sold', 'line',\n",
       "       'line credit', 'loan', 'loan apply', 'loan lease',\n",
       "       'loan modification', 'loan servicing', 'lost', 'lost stolen',\n",
       "       'low', 'management', 'managing', 'managing line', 'managing loan',\n",
       "       'managing opening', 'marketing', 'marketing disclosure',\n",
       "       'modification', 'modification collection', 'money',\n",
       "       'money available', 'money order', 'monitoring',\n",
       "       'monitoring identity', 'mortgage', 'mortgage broker', 'opening',\n",
       "       'opening closing', 'order', 'originator', 'originator mortgage',\n",
       "       'overdraft', 'overdraft saving', 'overlimit', 'overlimit fee',\n",
       "       'owed', 'pay', 'payment', 'payment acct', 'payment escrow',\n",
       "       'payment sending', 'payoff', 'payoff process', 'plan', 'practice',\n",
       "       'privacy', 'problem', 'problem caused', 'problem unable',\n",
       "       'process', 'process cost', 'processing', 'processing delay',\n",
       "       'promised', 'property', 'protection', 'protection debt', 'rate',\n",
       "       'receive', 'receive money', 'received', 'received loan',\n",
       "       'relation', 'repay', 'repay loan', 'repaying', 'repaying loan',\n",
       "       'report', 'reporting', 'reporting company', 'repossessed',\n",
       "       'repossessed sold', 'representation', 'reward', 'reward feature',\n",
       "       'sale', 'sale account', 'saving', 'saving reward', 'scam', 'score',\n",
       "       'sending', 'sending money', 'service', 'service customer',\n",
       "       'service issue', 'servicer', 'servicing', 'servicing payment',\n",
       "       'settlement', 'settlement process', 'sharing', 'sharing info',\n",
       "       'shopping', 'shopping line', 'shopping loan', 'sold',\n",
       "       'sold property', 'sold vehicle', 'statement',\n",
       "       'statement representation', 'stolen', 'stolen check',\n",
       "       'stolen money', 'stop', 'stop charge', 'tactic', 'taking',\n",
       "       'taking loan', 'term', 'term change', 'theft', 'theft fraud',\n",
       "       'transaction', 'transaction issue', 'transfer', 'transfer fee',\n",
       "       'unable', 'unable get', 'unable pay', 'unauthorized',\n",
       "       'unauthorized issue', 'underwriting', 'unsolicited',\n",
       "       'unsolicited issuance', 'use', 'use credit', 'using',\n",
       "       'using debit', 'vehicle', 'verification', 'verification debt',\n",
       "       'withdrawal', 'workout', 'workout plan', 'wrong', 'wrong amount',\n",
       "       'wrong day'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidv = TfidfVectorizer(max_features=None, strip_accents='unicode',\n",
    "                        analyzer='word', ngram_range=(1,2))\n",
    "\n",
    "df_vect = tfidv.fit_transform(df1['Issue'])\n",
    "print(df_vect)\n",
    "feature_names = tfidv.get_feature_names_out()\n",
    "feature_names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing\n",
    "\n",
    "Concat old data withvectorized data from Issue column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.concat([df1, pd.DataFrame(df_vect.toarray())], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Issue' 'index'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21316\\947629119.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Issue'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'index'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\Python\\Complaints_Prediction_NLP\\.venv\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m                     \u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marguments\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_format_argument_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mallow_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m                     \u001b[0mFutureWarning\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m                 )\n\u001b[1;32m--> 331\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\Python\\Complaints_Prediction_NLP\\.venv\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5395\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m250.0\u001b[0m   \u001b[1;36m150.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5396\u001b[0m         \u001b[0mfalcon\u001b[0m  \u001b[0mspeed\u001b[0m   \u001b[1;36m320.0\u001b[0m   \u001b[1;36m250.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5397\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5398\u001b[0m         \"\"\"\n\u001b[1;32m-> 5399\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   5400\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5401\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5402\u001b[0m             \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python\\Complaints_Prediction_NLP\\.venv\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m                     \u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marguments\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_format_argument_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mallow_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m                     \u001b[0mFutureWarning\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m                 )\n\u001b[1;32m--> 331\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\Python\\Complaints_Prediction_NLP\\.venv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4501\u001b[0m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4503\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4504\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4505\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4507\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4508\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python\\Complaints_Prediction_NLP\\.venv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4571\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m~\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4572\u001b[0m                 \u001b[1;31m# Check if label doesn't exist along axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4573\u001b[0m                 \u001b[0mlabels_missing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer_for\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4574\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"raise\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlabels_missing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4575\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4577\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_extension_array_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4578\u001b[0m                 \u001b[1;31m# GH#45860\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Issue' 'index'] not found in axis\""
     ]
    }
   ],
   "source": [
    "df1.drop(['Issue','index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Company</th>\n",
       "      <th>State</th>\n",
       "      <th>Submitted via</th>\n",
       "      <th>Company response to consumer</th>\n",
       "      <th>Timely response?</th>\n",
       "      <th>Consumer disputed?</th>\n",
       "      <th>days_to_forward_complaint</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>301</th>\n",
       "      <th>302</th>\n",
       "      <th>303</th>\n",
       "      <th>304</th>\n",
       "      <th>305</th>\n",
       "      <th>306</th>\n",
       "      <th>307</th>\n",
       "      <th>308</th>\n",
       "      <th>309</th>\n",
       "      <th>310</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bank account or service</td>\n",
       "      <td>TCF NATIONAL BANK</td>\n",
       "      <td>IL</td>\n",
       "      <td>Referral</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>0.272612</td>\n",
       "      <td>0.394111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>Ditech Financial LLC</td>\n",
       "      <td>WI</td>\n",
       "      <td>Web</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>TRANSUNION INTERMEDIATE HOLDINGS, INC.</td>\n",
       "      <td>MO</td>\n",
       "      <td>Web</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>AMERICAN EXPRESS COMPANY</td>\n",
       "      <td>CA</td>\n",
       "      <td>Web</td>\n",
       "      <td>Closed with non-monetary relief</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>CITIBANK, N.A.</td>\n",
       "      <td>NY</td>\n",
       "      <td>Web</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>Ocwen Financial Corporation</td>\n",
       "      <td>CA</td>\n",
       "      <td>Referral</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>Bank account or service</td>\n",
       "      <td>BANK OF AMERICA, NATIONAL ASSOCIATION</td>\n",
       "      <td>NJ</td>\n",
       "      <td>Web</td>\n",
       "      <td>Closed with monetary relief</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>20</td>\n",
       "      <td>0.272612</td>\n",
       "      <td>0.394111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>JPMORGAN CHASE &amp; CO.</td>\n",
       "      <td>TX</td>\n",
       "      <td>Referral</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>JPMORGAN CHASE &amp; CO.</td>\n",
       "      <td>GA</td>\n",
       "      <td>Referral</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>0.298425</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>FIRST NATIONAL BANK OF PENNSYLVANIA</td>\n",
       "      <td>PA</td>\n",
       "      <td>Web</td>\n",
       "      <td>Closed with non-monetary relief</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0.298425</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 319 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Product                                 Company State  \\\n",
       "0      Bank account or service                       TCF NATIONAL BANK    IL   \n",
       "1                     Mortgage                    Ditech Financial LLC    WI   \n",
       "2             Credit reporting  TRANSUNION INTERMEDIATE HOLDINGS, INC.    MO   \n",
       "3             Credit reporting                AMERICAN EXPRESS COMPANY    CA   \n",
       "4                     Mortgage                          CITIBANK, N.A.    NY   \n",
       "...                        ...                                     ...   ...   \n",
       "99995                 Mortgage             Ocwen Financial Corporation    CA   \n",
       "99996  Bank account or service   BANK OF AMERICA, NATIONAL ASSOCIATION    NJ   \n",
       "99997                 Mortgage                    JPMORGAN CHASE & CO.    TX   \n",
       "99998                 Mortgage                    JPMORGAN CHASE & CO.    GA   \n",
       "99999                 Mortgage     FIRST NATIONAL BANK OF PENNSYLVANIA    PA   \n",
       "\n",
       "      Submitted via     Company response to consumer Timely response?  \\\n",
       "0          Referral          Closed with explanation              Yes   \n",
       "1               Web          Closed with explanation              Yes   \n",
       "2               Web          Closed with explanation              Yes   \n",
       "3               Web  Closed with non-monetary relief              Yes   \n",
       "4               Web          Closed with explanation              Yes   \n",
       "...             ...                              ...              ...   \n",
       "99995      Referral          Closed with explanation              Yes   \n",
       "99996           Web      Closed with monetary relief              Yes   \n",
       "99997      Referral          Closed with explanation              Yes   \n",
       "99998      Referral          Closed with explanation              Yes   \n",
       "99999           Web  Closed with non-monetary relief              Yes   \n",
       "\n",
       "      Consumer disputed?  days_to_forward_complaint         0         1  ...  \\\n",
       "0                     No                          1  0.272612  0.394111  ...   \n",
       "1                     No                          0  0.000000  0.000000  ...   \n",
       "2                     No                          0  0.000000  0.000000  ...   \n",
       "3                     No                          3  0.000000  0.000000  ...   \n",
       "4                     No                          6  0.000000  0.000000  ...   \n",
       "...                  ...                        ...       ...       ...  ...   \n",
       "99995                Yes                          1  0.000000  0.000000  ...   \n",
       "99996                Yes                         20  0.272612  0.394111  ...   \n",
       "99997                Yes                          7  0.000000  0.000000  ...   \n",
       "99998                Yes                          4  0.298425  0.000000  ...   \n",
       "99999                Yes                          0  0.298425  0.000000  ...   \n",
       "\n",
       "       301  302  303  304  305  306  307  308  309  310  \n",
       "0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "99995  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "99996  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "99997  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "99998  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "99999  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[100000 rows x 319 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Columns: 630 entries, Product to 310\n",
      "dtypes: float64(622), int64(1), object(7)\n",
      "memory usage: 480.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df1.drop(['Consumer disputed?'],axis=1)\n",
    "y = df1['Consumer disputed?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Columns: 629 entries, Product to 310\n",
      "dtypes: float64(622), int64(1), object(6)\n",
      "memory usage: 479.9+ MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100000, 629), (100000,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([                     'Product',                      'Company',\n",
       "                              'State',                'Submitted via',\n",
       "       'Company response to consumer',             'Timely response?',\n",
       "          'days_to_forward_complaint',                              0,\n",
       "                                    1,                              2,\n",
       "       ...\n",
       "                                  301,                            302,\n",
       "                                  303,                            304,\n",
       "                                  305,                            306,\n",
       "                                  307,                            308,\n",
       "                                  309,                            310],\n",
       "      dtype='object', length=629)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intialize feature for transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns[317]\n",
    "X.columns = X.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Company'].dtype"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product object\n",
      "Company object\n",
      "State object\n",
      "Submitted via object\n",
      "Company response to consumer object\n",
      "Timely response? object\n",
      "days_to_forward_complaint int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Company</th>\n",
       "      <th>State</th>\n",
       "      <th>Submitted via</th>\n",
       "      <th>Company response to consumer</th>\n",
       "      <th>Timely response?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Payday loan</td>\n",
       "      <td>Mobiloans, LLC</td>\n",
       "      <td>FL</td>\n",
       "      <td>Web</td>\n",
       "      <td>Untimely response</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>M&amp;T BANK CORPORATION</td>\n",
       "      <td>DE</td>\n",
       "      <td>Web</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>TRANSUNION INTERMEDIATE HOLDINGS, INC.</td>\n",
       "      <td>MD</td>\n",
       "      <td>Referral</td>\n",
       "      <td>Closed with non-monetary relief</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>EQUIFAX, INC.</td>\n",
       "      <td>IL</td>\n",
       "      <td>Web</td>\n",
       "      <td>Closed with non-monetary relief</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Experian Information Solutions Inc.</td>\n",
       "      <td>AL</td>\n",
       "      <td>Web</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>NATIONSTAR MORTGAGE LLC</td>\n",
       "      <td>FL</td>\n",
       "      <td>Web</td>\n",
       "      <td>Closed with monetary relief</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>U.S. BANCORP</td>\n",
       "      <td>KY</td>\n",
       "      <td>Referral</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>EQUIFAX, INC.</td>\n",
       "      <td>TX</td>\n",
       "      <td>Web</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>Ocwen Financial Corporation</td>\n",
       "      <td>IL</td>\n",
       "      <td>Web</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>HW Holding, Inc</td>\n",
       "      <td>TX</td>\n",
       "      <td>Web</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Product                                 Company State  \\\n",
       "0           Payday loan                          Mobiloans, LLC    FL   \n",
       "1              Mortgage                    M&T BANK CORPORATION    DE   \n",
       "2      Credit reporting  TRANSUNION INTERMEDIATE HOLDINGS, INC.    MD   \n",
       "3      Credit reporting                           EQUIFAX, INC.    IL   \n",
       "4      Credit reporting     Experian Information Solutions Inc.    AL   \n",
       "...                 ...                                     ...   ...   \n",
       "99995          Mortgage                 NATIONSTAR MORTGAGE LLC    FL   \n",
       "99996   Debt collection                            U.S. BANCORP    KY   \n",
       "99997  Credit reporting                           EQUIFAX, INC.    TX   \n",
       "99998          Mortgage             Ocwen Financial Corporation    IL   \n",
       "99999   Debt collection                         HW Holding, Inc    TX   \n",
       "\n",
       "      Submitted via     Company response to consumer Timely response?  \n",
       "0               Web                Untimely response               No  \n",
       "1               Web          Closed with explanation              Yes  \n",
       "2          Referral  Closed with non-monetary relief              Yes  \n",
       "3               Web  Closed with non-monetary relief              Yes  \n",
       "4               Web          Closed with explanation              Yes  \n",
       "...             ...                              ...              ...  \n",
       "99995           Web      Closed with monetary relief               No  \n",
       "99996      Referral          Closed with explanation              Yes  \n",
       "99997           Web          Closed with explanation              Yes  \n",
       "99998           Web          Closed with explanation              Yes  \n",
       "99999           Web          Closed with explanation              Yes  \n",
       "\n",
       "[100000 rows x 6 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_columnms = ['Product','Company','State','Submitted via',\n",
    "            'Company response to consumer','Timely response?',\n",
    "            'days_to_forward_complaint' ]\n",
    "\n",
    "X_col = ['Product','Company','State','Submitted via',\n",
    "            'Company response to consumer','Timely response?']\n",
    "\n",
    "for i in x_columnms:\n",
    "    print(i,X[i].dtype)\n",
    "    \n",
    "X_test = X[X_col]\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1\n",
       "0      1.0  0.0\n",
       "1      0.0  1.0\n",
       "2      0.0  1.0\n",
       "3      0.0  1.0\n",
       "4      0.0  1.0\n",
       "...    ...  ...\n",
       "99995  1.0  0.0\n",
       "99996  0.0  1.0\n",
       "99997  0.0  1.0\n",
       "99998  0.0  1.0\n",
       "99999  0.0  1.0\n",
       "\n",
       "[100000 rows x 2 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = OneHotEncoder()\n",
    "encoded_data = encoder.fit_transform(X_test[['Timely response?']])\n",
    "pd.DataFrame(encoded_data.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Product_0                         float64\n",
       "Product_1                         float64\n",
       "Product_2                         float64\n",
       "Product_3                         float64\n",
       "Timely response?_0                float64\n",
       "Timely response?_1                float64\n",
       "Submitted via_0                   float64\n",
       "Submitted via_1                   float64\n",
       "Submitted via_2                   float64\n",
       "State_0                           float64\n",
       "State_1                           float64\n",
       "State_2                           float64\n",
       "State_3                           float64\n",
       "State_4                           float64\n",
       "State_5                           float64\n",
       "Company response to consumer_0    float64\n",
       "Company response to consumer_1    float64\n",
       "Company response to consumer_2    float64\n",
       "Company_0                         float64\n",
       "Company_1                         float64\n",
       "Company_2                         float64\n",
       "Company_3                         float64\n",
       "Company_4                         float64\n",
       "Company_5                         float64\n",
       "Company_6                         float64\n",
       "Company_7                         float64\n",
       "Company_8                         float64\n",
       "Company_9                         float64\n",
       "Company_10                        float64\n",
       "Company_11                        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from category_encoders import BinaryEncoder\n",
    "\n",
    "encoder = BinaryEncoder()\n",
    "\n",
    "df_encoded = encoder.fit_transform(X_test[['Product','Timely response?','Submitted via','State','Company response to consumer','Company']])\n",
    "pd.DataFrame(df_encoded).astype('float64').dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_features = ['Product','Timely response?','Submitted via','State','Company response to consumer','Company']\n",
    "# onehot_features = ['Timely response?']\n",
    "# numerical_features =[str(x) for x in range(311)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create column tansformer for transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_encoder_pipeline = Pipeline(steps=[\n",
    "    ('SimpleImputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('BinaryEncoder', BinaryEncoder())                               \n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        ('binary_encoder_pipeline', binary_encoder_pipeline, binary_features)\n",
    "    ]\n",
    ",remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>643</th>\n",
       "      <th>644</th>\n",
       "      <th>645</th>\n",
       "      <th>646</th>\n",
       "      <th>647</th>\n",
       "      <th>648</th>\n",
       "      <th>649</th>\n",
       "      <th>650</th>\n",
       "      <th>651</th>\n",
       "      <th>652</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 653 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9    ...  643  644  645  \\\n",
       "0      0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  1.0  0.0  ...  0.0  0.0  0.0   \n",
       "1      0.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "2      0.0  0.0  1.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3      0.0  0.0  1.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "4      0.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "99995  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...  0.0  0.0  0.0   \n",
       "99996  0.0  0.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "99997  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...  0.0  0.0  0.0   \n",
       "99998  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...  0.0  0.0  0.0   \n",
       "99999  0.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "       646  647  648  649  650  651  652  \n",
       "0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...    ...  ...  ...  ...  ...  ...  ...  \n",
       "99995  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "99996  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "99997  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "99998  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "99999  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[100000 rows x 653 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df = pd.DataFrame(X)\n",
    "X_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=653, step=1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.where(y.values == 'Yes', 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Imbalanced Dataset\n",
    "\n",
    "* Synthetic Minority oversampling Technique or SMOTE is another technique to oversample the minority class, duplicate the minority dataset.\n",
    "\n",
    "* SMOTE is one of the famous oversampling techniques and is very effective in handling class imbalance. Combine SMOTE to some undersampling technique(ENN, Tomek) to increase the effectiveness of handling the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\Complaints_Prediction_NLP\\.venv\\lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py:336: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "smt = SMOTETomek(random_state=42, sampling_strategy='minority', n_jobs=-1)\n",
    "X_res, y_res = smt.fit_resample(X_df,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((92746, 653), (92746,))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res.shape, y_res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_clf(true, prediction):\n",
    "    acc = accuracy_score(true, prediction)\n",
    "    f1 = f1_score(true, prediction)\n",
    "    precision = precision_score(true, prediction)\n",
    "    recall = recall_score(true, prediction)\n",
    "    roc_auc = roc_auc_score(true, prediction)\n",
    "    return (acc, f1, precision, recall, roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'K-Neighbor classification': KNeighborsClassifier(),\n",
    "    'XGBClassifier': XGBClassifier(),\n",
    "    'CatBoost Classifier': CatBoostClassifier(verbose=False),\n",
    "    'AdaBoost Classifier': AdaBoostClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_models(X, y, models):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                        y, \n",
    "                                                        test_size=0.2, \n",
    "                                                        random_state=42)\n",
    "    \n",
    "    models_list = []\n",
    "    accuracy_list = []\n",
    "    auc = []\n",
    "    \n",
    "    for i in range(len(list(models))):\n",
    "        model = list(models.values())[i]\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        \n",
    "        model_train_accuracy, model_train_f1, model_train_precision,\\\n",
    "        model_train_recall, model_train_rocauc_score = evaluate_clf(y_train, y_train_pred)\n",
    "        \n",
    "        model_test_accuracy, model_test_f1, model_test_precision,\\\n",
    "        model_test_recall, model_test_rocauc_score = evaluate_clf(y_test, y_test_pred)\n",
    "        \n",
    "        print(list(models.keys())[i])\n",
    "        models_list.append(list(models.keys())[i])\n",
    "        \n",
    "        print('Model Evalution on Training Data')\n",
    "        print('- Accuracy Score:', model_train_accuracy)\n",
    "        print('- F1 Score Score:', model_train_f1)\n",
    "        print('- Precision Score:', model_train_precision)\n",
    "        print('- Recall Score:', model_train_recall)\n",
    "        print('- ROC AUC Score:', model_train_rocauc_score)\n",
    "        print('------------------------------------------------------------------------------------------------')\n",
    "        print('Model Evalution on Testing Data')\n",
    "        print('- Accuracy Score:', model_test_accuracy)\n",
    "        print('- F1 Score Score:', model_test_f1)\n",
    "        print('- Precision Score:', model_test_precision)\n",
    "        print('- Recall Score:', model_test_recall)\n",
    "        print('- ROC AUC Score:', model_test_rocauc_score)\n",
    "        \n",
    "        auc.append(model_test_rocauc_score)\n",
    "        \n",
    "        print('='*35)\n",
    "        print()\n",
    "        \n",
    "    report = pd.DataFrame(list(zip(models_list, accuracy_list)),\n",
    "                          columns=['Model Name', 'Accuracy']).sort_values(by=['Accuracy'],ascending=False)\n",
    "    \n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Model Evalution on Training Data\n",
      "- Accuracy Score: 0.8694943123618524\n",
      "- F1 Score Score: 0.8677709650548281\n",
      "- Precision Score: 0.8784108816455172\n",
      "- Recall Score: 0.8573857196826596\n",
      "- ROC AUC Score: 0.8694812706335102\n",
      "------------------------------------------------------------------------------------------------\n",
      "Model Evalution on Testing Data\n",
      "- Accuracy Score: 0.5845283018867925\n",
      "- F1 Score Score: 0.5830673519069516\n",
      "- Precision Score: 0.5876772082878953\n",
      "- Recall Score: 0.5785292538915727\n",
      "- ROC AUC Score: 0.584554285852121\n",
      "===================================\n",
      "\n",
      "Decision Tree\n",
      "Model Evalution on Training Data\n",
      "- Accuracy Score: 0.869507790177368\n",
      "- F1 Score Score: 0.8621661636581062\n",
      "- Precision Score: 0.9124630868438498\n",
      "- Recall Score: 0.8171245075287388\n",
      "- ROC AUC Score: 0.8694513700334199\n",
      "------------------------------------------------------------------------------------------------\n",
      "Model Evalution on Testing Data\n",
      "- Accuracy Score: 0.5600539083557952\n",
      "- F1 Score Score: 0.5394729417075786\n",
      "- Precision Score: 0.5686414465857721\n",
      "- Recall Score: 0.5131508319914116\n",
      "- ROC AUC Score: 0.5602570619079961\n",
      "===================================\n",
      "\n",
      "Gradient Boosting\n",
      "Model Evalution on Training Data\n",
      "- Accuracy Score: 0.5999380020486279\n",
      "- F1 Score Score: 0.5609478308459183\n",
      "- Precision Score: 0.6207077154735016\n",
      "- Recall Score: 0.5116843866371633\n",
      "- ROC AUC Score: 0.5998429472633283\n",
      "------------------------------------------------------------------------------------------------\n",
      "Model Evalution on Testing Data\n",
      "- Accuracy Score: 0.6003234501347708\n",
      "- F1 Score Score: 0.5653142589118197\n",
      "- Precision Score: 0.622787753520217\n",
      "- Recall Score: 0.5175523349436393\n",
      "- ROC AUC Score: 0.6006819606499464\n",
      "===================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\Complaints_Prediction_NLP\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Model Evalution on Training Data\n",
      "- Accuracy Score: 0.5937516847269395\n",
      "- F1 Score Score: 0.5780676950642515\n",
      "- Precision Score: 0.6005817335660267\n",
      "- Recall Score: 0.5571806357601597\n",
      "- ROC AUC Score: 0.5937122953694439\n",
      "------------------------------------------------------------------------------------------------\n",
      "Model Evalution on Testing Data\n",
      "- Accuracy Score: 0.5916981132075472\n",
      "- F1 Score Score: 0.5798757488351453\n",
      "- Precision Score: 0.5999081831745667\n",
      "- Recall Score: 0.5611379495437466\n",
      "- ROC AUC Score: 0.5918304799153493\n",
      "===================================\n",
      "\n",
      "K-Neighbor classification\n",
      "Model Evalution on Training Data\n",
      "- Accuracy Score: 0.7016281201142919\n",
      "- F1 Score Score: 0.6951360581689985\n",
      "- Precision Score: 0.7097980763822487\n",
      "- Recall Score: 0.6810675157860651\n",
      "- ROC AUC Score: 0.7016059750291196\n",
      "------------------------------------------------------------------------------------------------\n",
      "Model Evalution on Testing Data\n",
      "- Accuracy Score: 0.5663611859838275\n",
      "- F1 Score Score: 0.5557273831878936\n",
      "- Precision Score: 0.5722898418837448\n",
      "- Recall Score: 0.5400966183574879\n",
      "- ROC AUC Score: 0.5664749469697564\n",
      "===================================\n",
      "\n",
      "XGBClassifier\n",
      "Model Evalution on Training Data\n",
      "- Accuracy Score: 0.638727155102701\n",
      "- F1 Score Score: 0.6100807331442286\n",
      "- Precision Score: 0.6617855903051725\n",
      "- Recall Score: 0.5658697177397592\n",
      "- ROC AUC Score: 0.6386486829853409\n",
      "------------------------------------------------------------------------------------------------\n",
      "Model Evalution on Testing Data\n",
      "- Accuracy Score: 0.6002695417789757\n",
      "- F1 Score Score: 0.5724006689348942\n",
      "- Precision Score: 0.6183653127336157\n",
      "- Recall Score: 0.5327965646806226\n",
      "- ROC AUC Score: 0.6005617907322982\n",
      "===================================\n",
      "\n",
      "CatBoost Classifier\n",
      "Model Evalution on Training Data\n",
      "- Accuracy Score: 0.6453447625208906\n",
      "- F1 Score Score: 0.6187150433245429\n",
      "- Precision Score: 0.6681061459506822\n",
      "- Recall Score: 0.5761239138647526\n",
      "- ROC AUC Score: 0.6452702072420321\n",
      "------------------------------------------------------------------------------------------------\n",
      "Model Evalution on Testing Data\n",
      "- Accuracy Score: 0.6023180592991914\n",
      "- F1 Score Score: 0.5776607316654262\n",
      "- Precision Score: 0.6188665358194309\n",
      "- Recall Score: 0.5415995705850778\n",
      "- ROC AUC Score: 0.6025810522118675\n",
      "===================================\n",
      "\n",
      "AdaBoost Classifier\n",
      "Model Evalution on Training Data\n",
      "- Accuracy Score: 0.5951533775405682\n",
      "- F1 Score Score: 0.5723641126391618\n",
      "- Precision Score: 0.6057738669238187\n",
      "- Recall Score: 0.5424469750121431\n",
      "- ROC AUC Score: 0.5950966093758545\n",
      "------------------------------------------------------------------------------------------------\n",
      "Model Evalution on Testing Data\n",
      "- Accuracy Score: 0.5939622641509434\n",
      "- F1 Score Score: 0.5754706346522377\n",
      "- Precision Score: 0.6057909101696927\n",
      "- Recall Score: 0.548040794417606\n",
      "- ROC AUC Score: 0.5941611660230964\n",
      "===================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = evaluation_models(X=X_res, y=y_res, models = models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
