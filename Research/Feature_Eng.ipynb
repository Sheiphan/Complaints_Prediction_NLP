{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "\n",
    "# NLP Module\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize, FreqDist\n",
    "import string\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Classification model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,ConfusionMatrixDisplay,\\\n",
    "                            precision_score,recall_score,f1_score,roc_auc_score, roc_curve\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Preprocessing models\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from category_encoders.binary import BinaryEncoder\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "# Hyperparameters tuning models\n",
    "from hyperopt import tpe,hp,Trials,space_eval\n",
    "from hyperopt.fmin import fmin\n",
    "from hyperopt.pyll import scope"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading a CSV file using the pd.read_csv() function. \n",
    "* However, the file path contains backslashes (\\) which can cause issues. It's recommended to either use forward slashes (/) or escape the backslashes (\\\\) in the file path to avoid any problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768358, 18)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Complaints.csv')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculates the percentage of missing values in each column of the DataFrame df and sorts them in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>85.881191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "      <td>78.651358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Company public response</th>\n",
       "      <td>74.528931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consumer consent provided?</th>\n",
       "      <td>61.237210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sub-issue</th>\n",
       "      <td>59.265342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sub-product</th>\n",
       "      <td>30.605525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <td>0.735334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZIP code</th>\n",
       "      <td>0.501980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date sent to company</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consumer disputed?</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timely response?</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Company response to consumer</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date received</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Submitted via</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Company</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Issue</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Complaint ID</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      0\n",
       "Tags                          85.881191\n",
       "Consumer complaint narrative  78.651358\n",
       "Company public response       74.528931\n",
       "Consumer consent provided?    61.237210\n",
       "Sub-issue                     59.265342\n",
       "Sub-product                   30.605525\n",
       "State                          0.735334\n",
       "ZIP code                       0.501980\n",
       "Date sent to company           0.000000\n",
       "Consumer disputed?             0.000000\n",
       "Timely response?               0.000000\n",
       "Company response to consumer   0.000000\n",
       "Date received                  0.000000\n",
       "Submitted via                  0.000000\n",
       "Product                        0.000000\n",
       "Company                        0.000000\n",
       "Issue                          0.000000\n",
       "Complaint ID                   0.000000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = df.isnull().sum().div(df.shape[0]).mul(100).to_frame().sort_values(by=0, ascending=False)\n",
    "missing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop unnecessary columns from the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "drop_columns = ['Tags','Consumer complaint narrative','Company public response',\n",
    "                'Consumer consent provided?','Sub-issue','Sub-product','Complaint ID','ZIP code']\n",
    "df.drop(drop_columns, axis=1,inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date received</th>\n",
       "      <th>Date sent to company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>2015-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-09-04</td>\n",
       "      <td>2013-09-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-06-10</td>\n",
       "      <td>2014-06-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-08</td>\n",
       "      <td>2014-01-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-09-11</td>\n",
       "      <td>2014-09-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Date received Date sent to company\n",
       "0    2015-01-04           2015-01-04\n",
       "1    2013-09-04           2013-09-03\n",
       "2    2014-06-10           2014-06-10\n",
       "3    2014-01-08           2014-01-08\n",
       "4    2014-09-11           2014-09-18"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Date received','Date sent to company']].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the number of days it took to forward a complaint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date received</th>\n",
       "      <th>Product</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Company</th>\n",
       "      <th>State</th>\n",
       "      <th>Submitted via</th>\n",
       "      <th>Date sent to company</th>\n",
       "      <th>Company response to consumer</th>\n",
       "      <th>Timely response?</th>\n",
       "      <th>Consumer disputed?</th>\n",
       "      <th>days_to_forward_complaint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Incorrect information on credit report</td>\n",
       "      <td>Experian Information Solutions Inc.</td>\n",
       "      <td>TX</td>\n",
       "      <td>Web</td>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-09-04</td>\n",
       "      <td>Credit card</td>\n",
       "      <td>Credit determination</td>\n",
       "      <td>CITIBANK, N.A.</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Web</td>\n",
       "      <td>2013-09-03</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-06-10</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>Disclosure verification of debt</td>\n",
       "      <td>SYNCHRONY FINANCIAL</td>\n",
       "      <td>CO</td>\n",
       "      <td>Web</td>\n",
       "      <td>2014-06-10</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Date received           Product                                   Issue  \\\n",
       "0    2015-01-04  Credit reporting  Incorrect information on credit report   \n",
       "1    2013-09-04       Credit card                    Credit determination   \n",
       "2    2014-06-10   Debt collection         Disclosure verification of debt   \n",
       "\n",
       "                               Company State Submitted via  \\\n",
       "0  Experian Information Solutions Inc.    TX           Web   \n",
       "1                       CITIBANK, N.A.    AZ           Web   \n",
       "2                  SYNCHRONY FINANCIAL    CO           Web   \n",
       "\n",
       "  Date sent to company Company response to consumer Timely response?  \\\n",
       "0           2015-01-04      Closed with explanation              Yes   \n",
       "1           2013-09-03      Closed with explanation              Yes   \n",
       "2           2014-06-10      Closed with explanation              Yes   \n",
       "\n",
       "  Consumer disputed?  days_to_forward_complaint  \n",
       "0                 No                          0  \n",
       "1                 No                         -1  \n",
       "2                 No                          0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['days_to_forward_complaint'] = pd.to_datetime(df['Date sent to company'])-pd.to_datetime(df['Date received'])\n",
    "df['days_to_forward_complaint'] = df['days_to_forward_complaint'].dt.days\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Date received','Date sent to company'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For models to reduce computation time we can use sample of the data for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 10)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.groupby('Consumer disputed?').sample(n=50000)\n",
    "df1.reset_index(inplace=True)\n",
    "df1.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text processing\n",
    "\n",
    "##### For Vectorization\n",
    "* TFIDF\n",
    "* CountVectorizer\n",
    "* NLTK/Scipy Library\n",
    "* Pretrained Glove\n",
    "\n",
    "##### Steps for text processing\n",
    "* Remove punctuation\n",
    "* Remove Stop Words\n",
    "* Lower Casing\n",
    "* Tokenization\n",
    "* Stemming/Lemmatization\n",
    "\n",
    "\n",
    "##### Note\n",
    "* `Issue` column has text which has to be preprocessed.\n",
    "* The text need to be transformed into vectors as the algorithm will be able to make predictions. In this case, it will be used the Term Frequency-Inverse Document Frequency (TFIDF) weight to evaluate how import a word is to a document in a collection of documents.\n",
    "* After removing the punctuation and lower casing the words, the importance of the word is determined in terms of the frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of stopword which will be remmoved\n",
    "stopwords_list = stopwords.words('english')+list(string.punctuation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In the `process_text` function, you can improve the readability of the code by using a list comprehension instead of two separate loops. This will make the code more concise. \n",
    "\n",
    "* In the `concat_strings` function, you can use the `join()` method to concatenate the `words` in the list. This method is more efficient than concatenating strings using the `+` operator inside a loop.\n",
    "\n",
    "* In the `lemmatizer_concat` function, there is a small issue. The lemmatization is being applied to the original `words_list` instead of the filtered `list_of_words`. Replace `words_list` with `list_of_words` in the for loop. You can try that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def process_text(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Tokenizes the input text, removes stopwords and non-alphabetic words.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to be processed.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of processed tokens.\n",
    "    \"\"\"\n",
    "\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stopwords_removed = [token.lower() for token in tokens if token.lower() not in stopwords_list]\n",
    "    stopwords_removed = [word for word in stopwords_removed if word.isalpha()]\n",
    "\n",
    "    return stopwords_removed\n",
    "\n",
    "def concat_strings(words: List[str]) -> str:\n",
    "    \"\"\"\n",
    "    Concatenates a list of words into a single string.\n",
    "\n",
    "    Args:\n",
    "        words (list): The list of words to be concatenated.\n",
    "\n",
    "    Returns:\n",
    "        str: The concatenated string.\n",
    "    \"\"\"\n",
    "\n",
    "    return ' '.join(words)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatizer_concat(words: List[str]) -> str:\n",
    "    \"\"\"\n",
    "    Lemmatizes each word in the given list and concatenates them into a single string.\n",
    "\n",
    "    Args:\n",
    "        words (list): The list of words to be lemmatized and concatenated.\n",
    "\n",
    "    Returns:\n",
    "        str: The lemmatized and concatenated string.\n",
    "    \"\"\"\n",
    "\n",
    "    words = [word for word in words if word is not np.nan]\n",
    "    lemmatized_list = []\n",
    "    for word in words:\n",
    "        lemmatized_list.append(lemmatizer.lemmatize(word))\n",
    "\n",
    "    return concat_strings(lemmatized_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data with text processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sheip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sheip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "C:\\Users\\sheip\\AppData\\Local\\Temp\\ipykernel_16280\\1594074003.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['Issue'].loc[i] = final_texts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Row Number 0\n",
      "Processed Row Number 5000\n",
      "Processed Row Number 10000\n",
      "Processed Row Number 15000\n",
      "Processed Row Number 20000\n",
      "Processed Row Number 25000\n",
      "Processed Row Number 30000\n",
      "Processed Row Number 35000\n",
      "Processed Row Number 40000\n",
      "Processed Row Number 45000\n",
      "Processed Row Number 50000\n",
      "Processed Row Number 55000\n",
      "Processed Row Number 60000\n",
      "Processed Row Number 65000\n",
      "Processed Row Number 70000\n",
      "Processed Row Number 75000\n",
      "Processed Row Number 80000\n",
      "Processed Row Number 85000\n",
      "Processed Row Number 90000\n",
      "Processed Row Number 95000\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "for i in range(len(df1)):\n",
    "    \n",
    "    # Iterate through all the rows and extract each 'Issue'\n",
    "    text = process_text(df1['Issue'].loc[i])\n",
    "    final_texts = lemmatizer_concat(text)\n",
    "    \n",
    "    # Change the 'Issue' column into the processed text\n",
    "    df1['Issue'].loc[i] = final_texts\n",
    "    if i % 5000 == 0:\n",
    "        print(f'Processed Row Number {i}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the TfidfVectorizer from scikit-learn to transform the 'Issue' column of the DataFrame df1 into a matrix of TF-IDF features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create a TfidfVectorizer object\n",
    "tfidv = TfidfVectorizer(max_features=None, strip_accents='unicode', analyzer='word', ngram_range=(1, 2))\n",
    "\n",
    "# Fit and transform the 'Issue' column of DataFrame 'df1'\n",
    "df_vect = tfidv.fit_transform(df1['Issue'])\n",
    "\n",
    "# Get the feature names\n",
    "feature_names = tfidv.get_feature_names_out()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing\n",
    "\n",
    "Concat old data withvectorized data from Issue column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.concat([df1, pd.DataFrame(df_vect.toarray())], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop(['Issue','index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Company</th>\n",
       "      <th>State</th>\n",
       "      <th>Submitted via</th>\n",
       "      <th>Company response to consumer</th>\n",
       "      <th>Timely response?</th>\n",
       "      <th>Consumer disputed?</th>\n",
       "      <th>days_to_forward_complaint</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>299</th>\n",
       "      <th>300</th>\n",
       "      <th>301</th>\n",
       "      <th>302</th>\n",
       "      <th>303</th>\n",
       "      <th>304</th>\n",
       "      <th>305</th>\n",
       "      <th>306</th>\n",
       "      <th>307</th>\n",
       "      <th>308</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>BANK OF AMERICA, NATIONAL ASSOCIATION</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Fax</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>FIFTH THIRD FINANCIAL CORPORATION</td>\n",
       "      <td>MI</td>\n",
       "      <td>Web</td>\n",
       "      <td>Closed with non-monetary relief</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0.299569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>Credit Protection Association, L.P.</td>\n",
       "      <td>TX</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Closed with non-monetary relief</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>Pinnacle Credit Services, LLC</td>\n",
       "      <td>NC</td>\n",
       "      <td>Web</td>\n",
       "      <td>Closed with non-monetary relief</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469132</td>\n",
       "      <td>0.469132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>Ocwen Financial Corporation</td>\n",
       "      <td>IL</td>\n",
       "      <td>Referral</td>\n",
       "      <td>Closed with non-monetary relief</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>LD Holdings Group, LLC</td>\n",
       "      <td>CA</td>\n",
       "      <td>Web</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>0.299569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>Dovenmuehle Mortgage, Inc.</td>\n",
       "      <td>TX</td>\n",
       "      <td>Web</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0.299569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>Credit card</td>\n",
       "      <td>HSBC NORTH AMERICA HOLDINGS INC.</td>\n",
       "      <td>VT</td>\n",
       "      <td>Web</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>Credit card</td>\n",
       "      <td>WELLS FARGO &amp; COMPANY</td>\n",
       "      <td>FL</td>\n",
       "      <td>Web</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>Consumer Loan</td>\n",
       "      <td>Service Finance Holdings, LLC</td>\n",
       "      <td>CA</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 317 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Product                                Company State  \\\n",
       "0             Mortgage  BANK OF AMERICA, NATIONAL ASSOCIATION    AZ   \n",
       "1             Mortgage      FIFTH THIRD FINANCIAL CORPORATION    MI   \n",
       "2      Debt collection    Credit Protection Association, L.P.    TX   \n",
       "3      Debt collection          Pinnacle Credit Services, LLC    NC   \n",
       "4             Mortgage            Ocwen Financial Corporation    IL   \n",
       "...                ...                                    ...   ...   \n",
       "99995         Mortgage                 LD Holdings Group, LLC    CA   \n",
       "99996         Mortgage             Dovenmuehle Mortgage, Inc.    TX   \n",
       "99997      Credit card       HSBC NORTH AMERICA HOLDINGS INC.    VT   \n",
       "99998      Credit card                  WELLS FARGO & COMPANY    FL   \n",
       "99999    Consumer Loan          Service Finance Holdings, LLC    CA   \n",
       "\n",
       "      Submitted via     Company response to consumer Timely response?  \\\n",
       "0               Fax          Closed with explanation              Yes   \n",
       "1               Web  Closed with non-monetary relief              Yes   \n",
       "2             Phone  Closed with non-monetary relief              Yes   \n",
       "3               Web  Closed with non-monetary relief              Yes   \n",
       "4          Referral  Closed with non-monetary relief              Yes   \n",
       "...             ...                              ...              ...   \n",
       "99995           Web          Closed with explanation              Yes   \n",
       "99996           Web          Closed with explanation              Yes   \n",
       "99997           Web          Closed with explanation              Yes   \n",
       "99998           Web          Closed with explanation               No   \n",
       "99999         Phone          Closed with explanation              Yes   \n",
       "\n",
       "      Consumer disputed?  days_to_forward_complaint         0    1  ...  299  \\\n",
       "0                     No                          7  0.000000  0.0  ...  0.0   \n",
       "1                     No                          0  0.299569  0.0  ...  0.0   \n",
       "2                     No                          6  0.000000  0.0  ...  0.0   \n",
       "3                     No                          0  0.000000  0.0  ...  0.0   \n",
       "4                     No                          5  0.000000  0.0  ...  0.0   \n",
       "...                  ...                        ...       ...  ...  ...  ...   \n",
       "99995                Yes                          3  0.299569  0.0  ...  0.0   \n",
       "99996                Yes                          0  0.299569  0.0  ...  0.0   \n",
       "99997                Yes                          0  0.000000  0.0  ...  0.0   \n",
       "99998                Yes                          0  0.000000  0.0  ...  0.0   \n",
       "99999                Yes                          4  0.000000  0.0  ...  0.0   \n",
       "\n",
       "       300       301       302  303  304  305  306  307  308  \n",
       "0      0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1      0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2      0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3      0.0  0.469132  0.469132  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4      0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...    ...       ...       ...  ...  ...  ...  ...  ...  ...  \n",
       "99995  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "99996  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "99997  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "99998  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "99999  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[100000 rows x 317 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Columns: 317 entries, Product to 308\n",
      "dtypes: float64(309), int64(1), object(7)\n",
      "memory usage: 241.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = df1.drop(['Consumer disputed?'], axis=1)\n",
    "y = df1['Consumer disputed?']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Columns: 316 entries, Product to 308\n",
      "dtypes: float64(309), int64(1), object(6)\n",
      "memory usage: 241.1+ MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100000, 316), (100000,))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([                     'Product',                      'Company',\n",
       "                              'State',                'Submitted via',\n",
       "       'Company response to consumer',             'Timely response?',\n",
       "          'days_to_forward_complaint',                              0,\n",
       "                                    1,                              2,\n",
       "       ...\n",
       "                                  299,                            300,\n",
       "                                  301,                            302,\n",
       "                                  303,                            304,\n",
       "                                  305,                            306,\n",
       "                                  307,                            308],\n",
       "      dtype='object', length=316)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intialize feature for transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns = X.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Company'].dtype"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product object\n",
      "Company object\n",
      "State object\n",
      "Submitted via object\n",
      "Company response to consumer object\n",
      "Timely response? object\n",
      "days_to_forward_complaint int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Company</th>\n",
       "      <th>State</th>\n",
       "      <th>Submitted via</th>\n",
       "      <th>Company response to consumer</th>\n",
       "      <th>Timely response?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>BANK OF AMERICA, NATIONAL ASSOCIATION</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Fax</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>FIFTH THIRD FINANCIAL CORPORATION</td>\n",
       "      <td>MI</td>\n",
       "      <td>Web</td>\n",
       "      <td>Closed with non-monetary relief</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>Credit Protection Association, L.P.</td>\n",
       "      <td>TX</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Closed with non-monetary relief</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>Pinnacle Credit Services, LLC</td>\n",
       "      <td>NC</td>\n",
       "      <td>Web</td>\n",
       "      <td>Closed with non-monetary relief</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>Ocwen Financial Corporation</td>\n",
       "      <td>IL</td>\n",
       "      <td>Referral</td>\n",
       "      <td>Closed with non-monetary relief</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>LD Holdings Group, LLC</td>\n",
       "      <td>CA</td>\n",
       "      <td>Web</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>Dovenmuehle Mortgage, Inc.</td>\n",
       "      <td>TX</td>\n",
       "      <td>Web</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>Credit card</td>\n",
       "      <td>HSBC NORTH AMERICA HOLDINGS INC.</td>\n",
       "      <td>VT</td>\n",
       "      <td>Web</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>Credit card</td>\n",
       "      <td>WELLS FARGO &amp; COMPANY</td>\n",
       "      <td>FL</td>\n",
       "      <td>Web</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>Consumer Loan</td>\n",
       "      <td>Service Finance Holdings, LLC</td>\n",
       "      <td>CA</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Product                                Company State  \\\n",
       "0             Mortgage  BANK OF AMERICA, NATIONAL ASSOCIATION    AZ   \n",
       "1             Mortgage      FIFTH THIRD FINANCIAL CORPORATION    MI   \n",
       "2      Debt collection    Credit Protection Association, L.P.    TX   \n",
       "3      Debt collection          Pinnacle Credit Services, LLC    NC   \n",
       "4             Mortgage            Ocwen Financial Corporation    IL   \n",
       "...                ...                                    ...   ...   \n",
       "99995         Mortgage                 LD Holdings Group, LLC    CA   \n",
       "99996         Mortgage             Dovenmuehle Mortgage, Inc.    TX   \n",
       "99997      Credit card       HSBC NORTH AMERICA HOLDINGS INC.    VT   \n",
       "99998      Credit card                  WELLS FARGO & COMPANY    FL   \n",
       "99999    Consumer Loan          Service Finance Holdings, LLC    CA   \n",
       "\n",
       "      Submitted via     Company response to consumer Timely response?  \n",
       "0               Fax          Closed with explanation              Yes  \n",
       "1               Web  Closed with non-monetary relief              Yes  \n",
       "2             Phone  Closed with non-monetary relief              Yes  \n",
       "3               Web  Closed with non-monetary relief              Yes  \n",
       "4          Referral  Closed with non-monetary relief              Yes  \n",
       "...             ...                              ...              ...  \n",
       "99995           Web          Closed with explanation              Yes  \n",
       "99996           Web          Closed with explanation              Yes  \n",
       "99997           Web          Closed with explanation              Yes  \n",
       "99998           Web          Closed with explanation               No  \n",
       "99999         Phone          Closed with explanation              Yes  \n",
       "\n",
       "[100000 rows x 6 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_columnms = ['Product','Company','State','Submitted via',\n",
    "            'Company response to consumer','Timely response?',\n",
    "            'days_to_forward_complaint' ]\n",
    "\n",
    "X_col = ['Product','Company','State','Submitted via',\n",
    "            'Company response to consumer','Timely response?']\n",
    "\n",
    "for i in x_columnms:\n",
    "    print(i,X[i].dtype)\n",
    "    \n",
    "X_test = X[X_col]\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1\n",
       "0      0.0  1.0\n",
       "1      0.0  1.0\n",
       "2      0.0  1.0\n",
       "3      0.0  1.0\n",
       "4      0.0  1.0\n",
       "...    ...  ...\n",
       "99995  0.0  1.0\n",
       "99996  0.0  1.0\n",
       "99997  0.0  1.0\n",
       "99998  1.0  0.0\n",
       "99999  0.0  1.0\n",
       "\n",
       "[100000 rows x 2 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = OneHotEncoder()\n",
    "encoded_data = encoder.fit_transform(X_test[['Timely response?']])\n",
    "pd.DataFrame(encoded_data.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Product_0                         float64\n",
       "Product_1                         float64\n",
       "Product_2                         float64\n",
       "Product_3                         float64\n",
       "Timely response?_0                float64\n",
       "Timely response?_1                float64\n",
       "Submitted via_0                   float64\n",
       "Submitted via_1                   float64\n",
       "Submitted via_2                   float64\n",
       "State_0                           float64\n",
       "State_1                           float64\n",
       "State_2                           float64\n",
       "State_3                           float64\n",
       "State_4                           float64\n",
       "State_5                           float64\n",
       "Company response to consumer_0    float64\n",
       "Company response to consumer_1    float64\n",
       "Company response to consumer_2    float64\n",
       "Company_0                         float64\n",
       "Company_1                         float64\n",
       "Company_2                         float64\n",
       "Company_3                         float64\n",
       "Company_4                         float64\n",
       "Company_5                         float64\n",
       "Company_6                         float64\n",
       "Company_7                         float64\n",
       "Company_8                         float64\n",
       "Company_9                         float64\n",
       "Company_10                        float64\n",
       "Company_11                        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from category_encoders import BinaryEncoder\n",
    "\n",
    "encoder = BinaryEncoder()\n",
    "\n",
    "df_encoded = encoder.fit_transform(X_test[['Product','Timely response?','Submitted via','State','Company response to consumer','Company']])\n",
    "pd.DataFrame(df_encoded).astype('float64').dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of binary features for encoding\n",
    "binary_features = ['Product','Timely response?','Submitted via','State','Company response to consumer','Company']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create column tansformer for transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_encoder_pipeline = Pipeline(steps=[\n",
    "    ('SimpleImputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('BinaryEncoder', BinaryEncoder())                               \n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        ('binary_encoder_pipeline', binary_encoder_pipeline, binary_features)\n",
    "    ]\n",
    ",remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>330</th>\n",
       "      <th>331</th>\n",
       "      <th>332</th>\n",
       "      <th>333</th>\n",
       "      <th>334</th>\n",
       "      <th>335</th>\n",
       "      <th>336</th>\n",
       "      <th>337</th>\n",
       "      <th>338</th>\n",
       "      <th>339</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469132</td>\n",
       "      <td>0.469132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 340 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9    ...  330  331  \\\n",
       "0      0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  1.0  0.0  ...  0.0  0.0   \n",
       "1      0.0  0.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  ...  0.0  0.0   \n",
       "2      0.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  1.0  0.0  ...  0.0  0.0   \n",
       "3      0.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  ...  0.0  0.0   \n",
       "4      0.0  0.0  0.0  1.0  0.0  1.0  1.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "99995  0.0  0.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  ...  0.0  0.0   \n",
       "99996  0.0  0.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  ...  0.0  0.0   \n",
       "99997  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  ...  0.0  0.0   \n",
       "99998  0.0  1.0  0.0  1.0  1.0  0.0  0.0  1.0  0.0  0.0  ...  0.0  0.0   \n",
       "99999  0.0  1.0  1.0  0.0  0.0  1.0  0.0  1.0  1.0  0.0  ...  0.0  0.0   \n",
       "\n",
       "            332       333  334  335  336  337  338  339  \n",
       "0      0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1      0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2      0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3      0.469132  0.469132  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4      0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...         ...       ...  ...  ...  ...  ...  ...  ...  \n",
       "99995  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "99996  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "99997  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "99998  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "99999  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[100000 rows x 340 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df = pd.DataFrame(X)\n",
    "X_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=340, step=1)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.where(y.values == 'Yes', 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Imbalanced Dataset\n",
    "\n",
    "* Synthetic Minority oversampling Technique or SMOTE is another technique to oversample the minority class, duplicate the minority dataset.\n",
    "\n",
    "* SMOTE is one of the famous oversampling techniques and is very effective in handling class imbalance. Combine SMOTE to some undersampling technique(ENN, Tomek) to increase the effectiveness of handling the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\Complaints_Prediction_NLP\\.venv\\lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py:336: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "smt = SMOTETomek(random_state=42, sampling_strategy='minority', n_jobs=-1)\n",
    "X_res, y_res = smt.fit_resample(X_df,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((93086, 340), (93086,))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res.shape, y_res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "def evaluate_clf(true: List[int], prediction: List[int]) -> Tuple[float, float, float, float, float]:\n",
    "    \"\"\"\n",
    "    Evaluate the performance of a classification model.\n",
    "\n",
    "    Args:\n",
    "        true (List[int]): List of true labels.\n",
    "        prediction (List[int]): List of predicted labels.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, float, float, float, float]: Tuple containing accuracy, F1 score,\n",
    "        precision, recall, and ROC AUC score.\n",
    "    \"\"\"\n",
    "    acc = accuracy_score(true, prediction)\n",
    "    f1 = f1_score(true, prediction)\n",
    "    precision = precision_score(true, prediction)\n",
    "    recall = recall_score(true, prediction)\n",
    "    roc_auc = roc_auc_score(true, prediction)\n",
    "    return acc, f1, precision, recall, roc_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'K-Neighbor classification': KNeighborsClassifier(),\n",
    "    'XGBClassifier': XGBClassifier(),\n",
    "    'CatBoost Classifier': CatBoostClassifier(verbose=False),\n",
    "    'AdaBoost Classifier': AdaBoostClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any\n",
    "\n",
    "def evaluation_models(X: Any, y: Any, models: Dict[str, Any]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Evaluate multiple models on training and testing data.\n",
    "    \n",
    "    Args:\n",
    "        X (Any): Input features.\n",
    "        y (Any): Target variable.\n",
    "        models (Dict[str, Any]): Dictionary of models to evaluate.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Evaluation report containing model names and accuracy scores.\n",
    "    \"\"\"\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    models_list = []\n",
    "    accuracy_list = []\n",
    "    auc = []\n",
    "    \n",
    "    for i in range(len(list(models))):\n",
    "        # Fit the model on the training data\n",
    "        model = list(models.values())[i]\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        \n",
    "        # Evaluate the model on the training data\n",
    "        model_train_accuracy, model_train_f1, model_train_precision, model_train_recall, model_train_rocauc_score = evaluate_clf(y_train, y_train_pred)\n",
    "        \n",
    "        # Evaluate the model on the testing data\n",
    "        model_test_accuracy, model_test_f1, model_test_precision, model_test_recall, model_test_rocauc_score = evaluate_clf(y_test, y_test_pred)\n",
    "        \n",
    "        # Print the model name\n",
    "        print(list(models.keys())[i])\n",
    "        models_list.append(list(models.keys())[i])\n",
    "        \n",
    "        # Print evaluation results on the training data\n",
    "        print('Model Evaluation on Training Data')\n",
    "        print('- Accuracy Score:', model_train_accuracy)\n",
    "        print('- F1 Score:', model_train_f1)\n",
    "        print('- Precision Score:', model_train_precision)\n",
    "        print('- Recall Score:', model_train_recall)\n",
    "        print('- ROC AUC Score:', model_train_rocauc_score)\n",
    "        \n",
    "        print('------------------------------------------------------------------------------------------------')\n",
    "        \n",
    "        # Print evaluation results on the testing data\n",
    "        print('Model Evaluation on Testing Data')\n",
    "        print('- Accuracy Score:', model_test_accuracy)\n",
    "        print('- F1 Score:', model_test_f1)\n",
    "        print('- Precision Score:', model_test_precision)\n",
    "        print('- Recall Score:', model_test_recall)\n",
    "        print('- ROC AUC Score:', model_test_rocauc_score)\n",
    "        \n",
    "        auc.append(model_test_rocauc_score)\n",
    "        \n",
    "        print('='*35)\n",
    "        print()\n",
    "        \n",
    "    report = pd.DataFrame(list(zip(models_list, accuracy_list)), columns=['Model Name', 'Accuracy']).sort_values(by=['Accuracy'], ascending=False)\n",
    "    \n",
    "    return report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Model Evaluation on Training Data\n",
      "- Accuracy Score: 0.8708950116087125\n",
      "- F1 Score: 0.868658183605483\n",
      "- Precision Score: 0.8838876385763107\n",
      "- Recall Score: 0.8539446487531206\n",
      "- ROC AUC Score: 0.8708934193846118\n",
      "------------------------------------------------------------------------------------------------\n",
      "Model Evaluation on Testing Data\n",
      "- Accuracy Score: 0.579311825648183\n",
      "- F1 Score: 0.571912383241383\n",
      "- Precision Score: 0.5823784625653576\n",
      "- Recall Score: 0.5618158403090792\n",
      "- ROC AUC Score: 0.5793184023798644\n",
      "===================================\n",
      "\n",
      "Decision Tree\n",
      "Model Evaluation on Training Data\n",
      "- Accuracy Score: 0.8709084320856764\n",
      "- F1 Score: 0.8636357192475085\n",
      "- Precision Score: 0.9150994412065132\n",
      "- Recall Score: 0.8176522696158699\n",
      "- ROC AUC Score: 0.8709034294939253\n",
      "------------------------------------------------------------------------------------------------\n",
      "Model Evaluation on Testing Data\n",
      "- Accuracy Score: 0.5591282409147029\n",
      "- F1 Score: 0.5365908706200982\n",
      "- Precision Score: 0.5657346817370613\n",
      "- Recall Score: 0.5103026400515132\n",
      "- ROC AUC Score: 0.5591465944323725\n",
      "===================================\n",
      "\n",
      "Gradient Boosting\n",
      "Model Evaluation on Training Data\n",
      "- Accuracy Score: 0.6003784574503778\n",
      "- F1 Score: 0.5589180701832348\n",
      "- Precision Score: 0.6235457429931254\n",
      "- Recall Score: 0.5064290124285292\n",
      "- ROC AUC Score: 0.600369632354898\n",
      "------------------------------------------------------------------------------------------------\n",
      "Model Evaluation on Testing Data\n",
      "- Accuracy Score: 0.5946642331848193\n",
      "- F1 Score: 0.55056246651985\n",
      "- Precision Score: 0.6180676199385273\n",
      "- Recall Score: 0.4963511483150891\n",
      "- ROC AUC Score: 0.5947011890216838\n",
      "===================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\Complaints_Prediction_NLP\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Model Evaluation on Training Data\n",
      "- Accuracy Score: 0.5898568035107967\n",
      "- F1 Score: 0.5771215874026209\n",
      "- Precision Score: 0.5955563171121773\n",
      "- Recall Score: 0.5597938421066759\n",
      "- ROC AUC Score: 0.5898539795611211\n",
      "------------------------------------------------------------------------------------------------\n",
      "Model Evaluation on Testing Data\n",
      "- Accuracy Score: 0.5869343496698696\n",
      "- F1 Score: 0.5728559533721898\n",
      "- Precision Score: 0.5933080372542255\n",
      "- Recall Score: 0.5537669027688346\n",
      "- ROC AUC Score: 0.586946817295705\n",
      "===================================\n",
      "\n",
      "K-Neighbor classification\n",
      "Model Evaluation on Training Data\n",
      "- Accuracy Score: 0.701434648987425\n",
      "- F1 Score: 0.6989621250050744\n",
      "- Precision Score: 0.7047314996725605\n",
      "- Recall Score: 0.6932864467291225\n",
      "- ROC AUC Score: 0.701433883590004\n",
      "------------------------------------------------------------------------------------------------\n",
      "Model Evaluation on Testing Data\n",
      "- Accuracy Score: 0.5569810510494391\n",
      "- F1 Score: 0.549828178694158\n",
      "- Precision Score: 0.5590682196339434\n",
      "- Recall Score: 0.5408886027044431\n",
      "- ROC AUC Score: 0.5569871001923031\n",
      "===================================\n",
      "\n",
      "XGBClassifier\n",
      "Model Evaluation on Training Data\n",
      "- Accuracy Score: 0.6385328734583227\n",
      "- F1 Score: 0.606066810975253\n",
      "- Precision Score: 0.6657990295317973\n",
      "- Recall Score: 0.5561699728880896\n",
      "- ROC AUC Score: 0.6385251367392675\n",
      "------------------------------------------------------------------------------------------------\n",
      "Model Evaluation on Testing Data\n",
      "- Accuracy Score: 0.5996027698749262\n",
      "- F1 Score: 0.5621881786699537\n",
      "- Precision Score: 0.6204171524808914\n",
      "- Recall Score: 0.5139514917364241\n",
      "- ROC AUC Score: 0.5996349661453036\n",
      "===================================\n",
      "\n",
      "CatBoost Classifier\n",
      "Model Evaluation on Training Data\n",
      "- Accuracy Score: 0.6456323057721471\n",
      "- F1 Score: 0.6183310928985444\n",
      "- Precision Score: 0.6698715941121203\n",
      "- Recall Score: 0.5741551016025555\n",
      "- ROC AUC Score: 0.6456255915956954\n",
      "------------------------------------------------------------------------------------------------\n",
      "Model Evaluation on Testing Data\n",
      "- Accuracy Score: 0.5986365344355574\n",
      "- F1 Score: 0.5664250507393447\n",
      "- Precision Score: 0.616122114292923\n",
      "- Recall Score: 0.524146812620734\n",
      "- ROC AUC Score: 0.5986645350827867\n",
      "===================================\n",
      "\n",
      "AdaBoost Classifier\n",
      "Model Evaluation on Training Data\n",
      "- Accuracy Score: 0.5878839933971254\n",
      "- F1 Score: 0.5638192096815431\n",
      "- Precision Score: 0.598720926724788\n",
      "- Recall Score: 0.5327624620835906\n",
      "- ROC AUC Score: 0.587878815582858\n",
      "------------------------------------------------------------------------------------------------\n",
      "Model Evaluation on Testing Data\n",
      "- Accuracy Score: 0.5890815395351334\n",
      "- F1 Score: 0.5633947413448925\n",
      "- Precision Score: 0.6012172854534388\n",
      "- Recall Score: 0.5300493668169135\n",
      "- ROC AUC Score: 0.5891037296977919\n",
      "===================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = evaluation_models(X=X_res, y=y_res, models = models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
